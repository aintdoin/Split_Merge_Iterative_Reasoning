""" 
å¤„ç†2WikiMultihopæ•°æ®ï¼Œå°†ä¸‰å…ƒç»„evidencesé€šè¿‡LLM APIè½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€å¥å­ï¼Œå¹¶ç”Ÿæˆanswerable=trueçš„æ ·æœ¬ã€‚

æµç¨‹:
1) é’ˆå¯¹åŸå§‹æ•°æ®ï¼ŒæŒ‰ format æµç¨‹è½¬æ¢åˆ°ç›®æ ‡æ ¼å¼ï¼Œç›´æ¥å°† evidences ä¸‰å…ƒç»„ç”¨ LLM API è½¬æ¢ä¸ºå¥å­
2) èµ‹äºˆ answerable=Trueï¼Œä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶
"""

import os
import sys

# CRITICAL: Must set this before ANY imports that might use torch/CUDA
os.environ['VLLM_WORKER_MULTIPROC_METHOD'] = 'spawn'

import ast
import json
import argparse
import random
from typing import Any, List, Tuple

import numpy as np
import pandas as pd
from datasets import Dataset
from tqdm import tqdm

# Add parent directory to path to import verl modules
# File is in data_preprocess/, so we need to go up one level to reach project root
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# =========================
# Prompt & dataset helpers
# =========================

def make_prefix_unified(dp: dict, template_type: str) -> str:
    """ç»Ÿä¸€çš„promptå‰ç¼€ï¼Œç”¨äºanswerableå’Œunanswerableæ ·æœ¬"""
    question = dp.get('question', 'no question')
    documents_str = dp.get('documents', '[]')
    
    # è§£æå¹¶æ ¼å¼åŒ–documents
    try:
        documents_list = ast.literal_eval(documents_str) if isinstance(documents_str, str) else documents_str
    except Exception:
        documents_list = []
    
    formatted_docs = []
    for doc in documents_list:
        if isinstance(doc, list) and len(doc) == 2:
            title, sentences = doc
            if isinstance(sentences, list):
                text = ' '.join(str(s) for s in sentences)
            else:
                text = str(sentences)
            formatted_docs.append(f"Document '{title}': {text}")
    
    documents_context = "\n".join(formatted_docs) if formatted_docs else "No references provided."
    
    user_content = f"""**References:**
{documents_context}

**Question:**
{question}"""
    
    return user_content


def gen_from_jsonl(path: str):
    """ä»JSONLæ–‡ä»¶åŠ è½½æ•°æ®å¹¶è½¬æ¢ä¸ºdatasetæ ¼å¼ï¼ˆ2WikiMultihopç‰ˆæœ¬ï¼‰"""
    with open(path) as f:
        for line in f:
            data = json.loads(line)
            # 2wikimultihop: è‹¥æœ‰supporting_factsï¼Œä¿æŒå­—ç¬¦ä¸²å½¢å¼ä¾¿äºåç»­è§£æ
            if 'supporting_facts' in data:
                data['supporting_facts'] = str(data['supporting_facts'])
            # evidenceså¯èƒ½æ˜¯ä¸‰å…ƒç»„åˆ—è¡¨ï¼Œè¿™é‡Œç›´æ¥è½¬ä¸ºå­—ç¬¦ä¸²ä¿å­˜ï¼ˆç¨åå†ç»“æ„åŒ–å¤„ç†ï¼‰
            if 'evidences' in data:
                try:
                    data['evidences'] = str(data['evidences'])
                except Exception:
                    data['evidences'] = '[]'
            # ç»Ÿä¸€å°†contextæ”¹ä¸ºdocuments
            if 'context' in data:
                data['documents'] = str(data['context'])
                del data['context']

            # ç®€å•è®¾ç½® sample_id
            if '_id' in data:
                extra_info = data.get('extra_info', {})
                if not isinstance(extra_info, dict):
                    extra_info = {}
                extra_info['sample_id'] = str(data['_id'])
                data['extra_info'] = extra_info
            yield data


# =========================
# Evidence conversion via API
# =========================


def to_list(value: Any) -> List[Any]:
    if isinstance(value, list):
        return value
    if value is None:
        return []
    if isinstance(value, str):
        s = value.strip()
        if not s:
            return []
        try:
            return list(ast.literal_eval(s))
        except Exception:
            try:
                return list(json.loads(s))
            except Exception:
                return []
    return []


def clean_evidence_items(items: List[Any]) -> List[List[Any]]:
    result: List[List[Any]] = []
    for item in items:
        if isinstance(item, list) and len(item) == 3:
            result.append(item)
    return result


class TripleSentenceConverter:
    """
    ç”¨äºå°† (subject, relation, object) ä¸‰å…ƒç»„è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€å¥å­ã€‚
    ä¼˜å…ˆè°ƒç”¨ Chat Completions APIï¼›è‹¥ä¸å¯ç”¨åˆ™å›é€€ä¸ºç¡®å®šæ€§æ¨¡æ¿ã€‚
    
    é€šè¿‡ä»¥ä¸‹ç¯å¢ƒå˜é‡é…ç½®:
      LLM_JUDGE_API_BASE, LLM_JUDGE_MODEL_NAME, LLM_JUDGE_API_KEY, LLM_JUDGE_TIMEOUT, LLM_JUDGE_MAX_WORKERS
    """
    def __init__(self):
        self.api_base = os.environ.get('LLM_JUDGE_API_BASE', '').strip()
        self.model_name = os.environ.get('LLM_JUDGE_MODEL_NAME', '').strip() or 'llm-judge'
        self.api_key = os.environ.get('LLM_JUDGE_API_KEY', '').strip()
        try:
            self.timeout = float(os.environ.get('LLM_JUDGE_TIMEOUT', '60'))
        except Exception:
            self.timeout = 60.0
        try:
            self.max_workers = int(os.environ.get('LLM_JUDGE_MAX_WORKERS', '8'))
        except Exception:
            self.max_workers = 8

        self.requests = requests if REQUESTS_AVAILABLE else None
        self.use_api = bool(self.api_base and self.requests)

    def _build_messages(self, subject: str, relation: str, obj: str) -> list:
        system_content = (
            "You are an expert at converting knowledge triples into clear, natural English sentences.\n\n"
            "Task Instructions:\n"
            "1. Transform the triple into ONE grammatically correct sentence\n"
            "2. Maintain the semantic relationship between the subject and object\n"
            "3. Use appropriate phrasing based on the relation type\n"
            "4. Return ONLY the resulting sentence, nothing else\n\n"
            "Example:\n"
            "Triple: ['Stuart Rosenberg', 'director', 'Move (1970 film)']\n"
            "Output: Stuart Rosenberg is the director of Move (1970 film).\n\n"
            "Triple: ['Jean-Daniel Pollet', 'country of citizenship', 'French']\n"
            "Output: Jean-Daniel Pollet's country of citizenship is France."
        )
        user_content = (
            "Convert the following knowledge triple into a single, natural English sentence:\n"
            f"['{subject}', '{relation}', '{obj}']"
        )
        return [
            {"role": "system", "content": system_content},
            {"role": "user", "content": user_content},
        ]

    def _call_chat(self, messages: list) -> str:
        assert self.requests is not None
        base = self.api_base.rstrip('/')
        url = base + '/v1/chat/completions'
        headers = {'Content-Type': 'application/json'}
        if self.api_key:
            headers['Authorization'] = f'Bearer {self.api_key}'
        payload = {
            'model': self.model_name,
            'messages': messages,
            'temperature': 0.0,
            'max_tokens': 80,
            'stream': False,
        }
        resp = self.requests.post(url, json=payload, headers=headers, timeout=self.timeout)
        resp.raise_for_status()
        data = resp.json()
        text = data.get('choices', [{}])[0].get('message', {}).get('content', '')
        return text.strip() if text else ''

    def convert_triple(self, triple: List[Any]) -> str:
        subject, relation, obj = (str(triple[0]), str(triple[1]), str(triple[2]))
        if self.use_api:
            try:
                messages = self._build_messages(subject, relation, obj)
                out = self._call_chat(messages)
                if out:
                    return out
            except Exception:
                pass
        return f"{subject} {relation} {obj}."

    def convert_triples(self, triples: List[List[Any]]) -> List[str]:
        if not triples:
            return []
        # Simple sequential for determinism and avoiding too many threads in data preprocess
        return [self.convert_triple(t) for t in triples]


def convert_evidences_to_sentences(evidences_cell: Any, converter: TripleSentenceConverter) -> List[str]:
    items = to_list(evidences_cell)
    triples = clean_evidence_items(items)
    sentences = converter.convert_triples(triples)
    return sentences


# =========================
# Best-of-N filtering utils
# =========================

def _has_valid_format(text: str) -> bool:
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦æœ‰æœ‰æ•ˆçš„<answer></answer>æ ¼å¼"""
    try:
        a_s = text.count('<answer>')
        a_e = text.count('</answer>')
        if a_s != 1 or a_e != 1:
            return False
        ps = text.find('<answer>')
        pe = text.find('</answer>')
        if ps == -1 or pe == -1 or ps >= pe:
            return False
        content = text[ps + len('<answer>'):pe].strip()
        if len(content) == 0:
            return False
        return True
    except Exception:
        return False


def _is_idk_answer(text: str) -> bool:
    """æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦æ˜¯IDK/ä¸ç¡®å®šçš„è¡¨è¾¾"""
    if not text:
        return False
    text_lower = text.strip().lower()
    idk_markers = [
        "i don't know", "i dont know", "i do not know",
        "i'm not sure", "i am not sure", "not sure",
        "cannot answer", "can't answer", "unable to answer",
        "cannot determine", "can't determine", "unable to determine",
        "insufficient information", "not enough information",
        "no sufficient information", "lack of information",
        "unknown", "unclear", "uncertain",
    ]
    return any(marker in text_lower for marker in idk_markers)


def call_api_for_candidates(prompt: str, api_base: str, model_name: str, api_key: str,
                            n: int, temperature: float, top_p: float, top_k: int, max_tokens: int) -> list:
    """
    è°ƒç”¨APIç”ŸæˆNä¸ªå€™é€‰å›ç­”ï¼Œè¿”å›ç”Ÿæˆçš„æ–‡æœ¬åˆ—è¡¨
    """
    if not REQUESTS_AVAILABLE:
        raise RuntimeError("requestsåº“ä¸å¯ç”¨ï¼Œæ— æ³•ä½¿ç”¨APIæ¨¡å¼")
    
    base = api_base.rstrip('/')
    chat_url = base + '/v1/chat/completions'
    comp_url = base + '/v1/completions'
    
    headers = {'Content-Type': 'application/json'}
    if api_key:
        headers['Authorization'] = f'Bearer {api_key}'
    
    # å°è¯•chat endpoint
    chat_payload = {
        'model': model_name,
        'messages': [
            {'role': 'system', 'content': 'You are a helpful assistant.'},
            {'role': 'user', 'content': prompt}
        ],
        'temperature': temperature,
        'top_p': top_p,
        'max_tokens': max_tokens,
        'n': n,
        'stream': False,
    }
    
    resp = requests.post(chat_url, json=chat_payload, headers=headers, timeout=120)
    if resp.status_code == 200:
        data = resp.json()
        candidates = []
        try:
            for choice in data.get('choices', []):
                text = choice.get('message', {}).get('content', '')
                if text and text.strip():
                    candidates.append(text.strip())
        except Exception:
            pass
        if candidates:
            return candidates
    
    # å¤‡ç”¨ï¼šcompletions endpoint
    comp_payload = {
        'model': model_name,
        'prompt': prompt,
        'temperature': temperature,
        'top_p': top_p,
        'max_tokens': max_tokens,
        'n': n,
        'stream': False,
    }
    
    resp2 = requests.post(comp_url, json=comp_payload, headers=headers, timeout=120)
    if resp2.status_code != 200:
        print(f"\nâš ï¸  APIé”™è¯¯è¯¦æƒ…:")
        print(f"  çŠ¶æ€: {resp2.status_code}")
        print(f"  URL: {comp_url}")
        print(f"  æ¨¡å‹: {model_name}")
        print(f"  å“åº”: {resp2.text[:300]}")
        return []
    
    data2 = resp2.json()
    candidates = []
    for choice in data2.get('choices', []):
        text = choice.get('text', '').strip()
        if text:
            candidates.append(text)
    
    return candidates if candidates else []


def evaluate_sample_best_of_n(sample_dict: dict, prompt: str, args, llm, sampling_params, postprocessor):
    """
    ä½¿ç”¨Best-of-Nç­–ç•¥è¯„ä¼°å•ä¸ªæ ·æœ¬
    è¿”å›: (is_truly_unanswerable: bool, best_reward: float)
    
    å¦‚æœNæ¬¡æ¨ç†ä¸­æœ‰ä»»ä½•ä¸€æ¬¡æˆåŠŸå›ç­”ï¼ˆéIDKä¸”æ­£ç¡®ï¼‰ï¼Œåˆ™è¿”å›Falseï¼ˆä¸æ˜¯çœŸæ­£çš„unanswerableï¼‰
    åªæœ‰Næ¬¡å…¨éƒ¨å¤±è´¥ï¼Œæ‰è¿”å›Trueï¼ˆæ˜¯çœŸæ­£çš„unanswerableï¼‰
    """
    import re
    
    # æå–å…ƒæ•°æ®
    extra_info = sample_dict.get('extra_info', {})
    if isinstance(extra_info, str):
        try:
            extra_info = json.loads(extra_info)
        except Exception:
            extra_info = {}
    
    question = sample_dict.get('question', '')
    ground_truth = sample_dict.get('answer', '')
    answer_aliases = extra_info.get('answer_aliases', [])
    if isinstance(answer_aliases, np.ndarray):
        answer_aliases = answer_aliases.tolist()
    elif answer_aliases is None:
        answer_aliases = []
    
    # ç”ŸæˆNä¸ªå€™é€‰å›ç­”
    if args.use_api:
        candidates = call_api_for_candidates(
            prompt, args.api_base, args.model_name, args.api_key,
            args.n_candidates, args.temperature, args.top_p, args.top_k, args.max_tokens
        )
        
        if not candidates:
            print(f"  âš ï¸ APIè°ƒç”¨å¤±è´¥ï¼Œè·³è¿‡æ­¤æ ·æœ¬")
            return False, -2
        
        has_correct_answer = False
        best_reward = -1
        
        for candidate_text in candidates:
            if not _has_valid_format(candidate_text):
                reward = -1
            else:
                match = re.search(r'<answer>\s*(.*?)\s*</answer>', candidate_text, re.DOTALL | re.IGNORECASE)
                extracted_answer = match.group(1).strip() if match else candidate_text.strip()
                
                is_idk = _is_idk_answer(extracted_answer)
                
                reward_scores = []
                all_answers = [ground_truth]
                if answer_aliases and len(answer_aliases) > 0:
                    all_answers.extend(answer_aliases)
                
                for ans in all_answers:
                    if ans:
                        try:
                            score = postprocessor.judge_answer_correctness(
                                predicted_answer=candidate_text,
                                ground_truth_answer=ans,
                                question=question,
                                answerable=False
                            )
                            reward_scores.append(score)
                        except Exception:
                            continue
                
                reward = max(reward_scores) if reward_scores else 0
                
                if reward >= 0.999 and not is_idk:
                    has_correct_answer = True
            
            if reward > best_reward:
                best_reward = reward
        
        return not has_correct_answer, best_reward
        
    else:
        outputs = llm.generate([prompt], sampling_params)
        output = outputs[0]
        
        has_correct_answer = False
        best_reward = -1
        
        for candidate_output in output.outputs:
            generated_text = candidate_output.text
            
            if not _has_valid_format(generated_text):
                reward = -1
            else:
                match = re.search(r'<answer>\s*(.*?)\s*</answer>', generated_text, re.DOTALL | re.IGNORECASE)
                extracted_answer = match.group(1).strip() if match else generated_text.strip()
                
                is_idk = _is_idk_answer(extracted_answer)
                
                reward_scores = []
                all_answers = [ground_truth]
                if answer_aliases and len(answer_aliases) > 0:
                    all_answers.extend(answer_aliases)
                
                for ans in all_answers:
                    if ans:
                        try:
                            score = postprocessor.judge_answer_correctness(
                                predicted_answer=generated_text,
                                ground_truth_answer=ans,
                                question=question,
                                answerable=False
                            )
                            reward_scores.append(score)
                        except Exception:
                            continue
                
                reward = max(reward_scores) if reward_scores else 0
                
                if reward >= 0.999 and not is_idk:
                    has_correct_answer = True
            
            if reward > best_reward:
                best_reward = reward
        
        return not has_correct_answer, best_reward


# =========================
# Sample builders
# =========================

def create_answerable_samples(dataset: Dataset, num_samples: int, template_type: str,
                              converter: TripleSentenceConverter) -> List[dict]:
    """åˆ›å»ºanswerableæ ·æœ¬ï¼Œå¹¶å°† evidences ä¸‰å…ƒç»„è½¬ä¸ºè‡ªç„¶è¯­è¨€å¥å­"""
    print(f"\n{'='*80}")
    print(f"æ­¥éª¤1: åˆ›å»º{num_samples}æ¡ANSWERABLEæ ·æœ¬")
    print(f"{'='*80}")
    
    answerable_dataset = dataset.select(range(num_samples))
    print(f"é€‰å–äº†{len(answerable_dataset)}ä¸ªæ ·æœ¬ç”¨äºanswerable")
    
    answerable_samples: List[dict] = []
    for i in range(len(answerable_dataset)):
        sample = answerable_dataset[i]
        evid_sentences = convert_evidences_to_sentences(sample.get('evidences', '[]'), converter)
        answerable_sample = {
            'question': sample.get('question', ''),
            'documents': sample.get('documents', '[]'),
            'answer': sample['answer'],
            'data_source': sample.get('data_source', '2wikimultihop'),
            'evidences': evid_sentences,  # å·²è½¬ä¸ºå¥å­åˆ—è¡¨
            'extra_info': sample.get('extra_info', {}),
        }
        if isinstance(answerable_sample['extra_info'], dict):
            answerable_sample['extra_info']['answerable'] = True
        else:
            answerable_sample['extra_info'] = {'answerable': True}
        answerable_samples.append(answerable_sample)
    
    print(f"âœ“ åˆ›å»ºäº†{len(answerable_samples)}æ¡answerableæ ·æœ¬")
    return answerable_samples


def create_unanswerable_samples_with_filter(dataset: Dataset, start_idx: int, num_samples: int,
                                            template_type: str, args, llm, sampling_params,
                                            postprocessor, converter: TripleSentenceConverter) -> List[dict]:
    """
    åˆ›å»ºunanswerableæ ·æœ¬å¹¶å®æ—¶è¿‡æ»¤ï¼ˆBest-of-Nï¼‰
    ä¸å†æ·»åŠ ä»»ä½•IDKå¥å­ï¼Œä»…å¯¹documentsè¿›è¡Œæ”¯æ’‘æ–‡æ¡£ç§»é™¤å¹¶è¿‡æ»¤
    """
    print(f"\n{'='*80}")
    print(f"æ­¥éª¤2: åˆ›å»ºå¹¶è¿‡æ»¤{num_samples}æ¡UNANSWERABLEæ ·æœ¬")
    print(f"{'='*80}")
    print(f"ä½¿ç”¨Best-of-{args.n_candidates}ç­–ç•¥")
    print(f"åªä¿ç•™{args.n_candidates}æ¬¡æ¨ç†å…¨éƒ¨å¤±è´¥çš„æ ·æœ¬\n")
    
    kept_samples: List[dict] = []
    removed_count = 0
    processed_count = 0
    
    pbar = tqdm(total=num_samples, desc="è¿‡æ»¤unanswerableæ ·æœ¬")
    
    idx = start_idx
    while len(kept_samples) < num_samples and idx < len(dataset) - 1:
        question_sample = dataset[idx]
        
        # è·å–é—®é¢˜å’ŒåŸå§‹æ–‡æ¡£
        question = question_sample.get('question', '')
        answer = question_sample['answer']
        
        # è§£æåŸå§‹æ–‡æ¡£
        try:
            original_documents = ast.literal_eval(question_sample.get('documents', '[]'))
        except Exception:
            original_documents = []
        
        # è§£æsupporting_factsä»¥è¯†åˆ«å…³é”®æ–‡æ¡£
        supporting_facts = question_sample.get('supporting_facts', None)
        if supporting_facts is None:
            extra_info = question_sample.get('extra_info', {})
            if isinstance(extra_info, str):
                try:
                    extra_info = ast.literal_eval(extra_info)
                except Exception:
                    extra_info = {}
            supporting_facts = extra_info.get('supporting_facts', [])
        
        if isinstance(supporting_facts, str):
            try:
                supporting_facts = ast.literal_eval(supporting_facts)
            except Exception:
                supporting_facts = []
        
        # æå–å”¯ä¸€çš„æ–‡æ¡£æ ‡é¢˜
        supporting_doc_titles: List[str] = []
        if isinstance(supporting_facts, list):
            for fact in supporting_facts:
                if isinstance(fact, list) and len(fact) >= 1:
                    title = fact[0]
                    if title not in supporting_doc_titles:
                        supporting_doc_titles.append(title)
        
        # ç­–ç•¥ï¼šç§»é™¤å…³é”®æ”¯æ’‘æ–‡æ¡£ï¼ˆé™¤äº†èµ·å§‹èŠ‚ç‚¹ï¼‰
        if supporting_doc_titles and len(supporting_doc_titles) > 1 and original_documents:
            removal_candidates = supporting_doc_titles[1:]
            if len(supporting_doc_titles) >= 4:
                num_to_remove = min(2, len(removal_candidates))
            else:
                num_to_remove = 1
            docs_to_remove = random.sample(removal_candidates, num_to_remove)
            modified_documents = original_documents.copy()
            for doc_title in docs_to_remove:
                modified_documents = [doc for doc in modified_documents 
                                      if not (isinstance(doc, list) and len(doc) >= 2 and doc[0] == doc_title)]
        else:
            modified_documents = original_documents
        
        # evidences è½¬å¥å­ï¼ˆä¸æ·»åŠ ä»»ä½•IDKå¥å­ï¼‰
        evid_sentences = convert_evidences_to_sentences(question_sample.get('evidences', '[]'), converter)
        
        unanswerable_sample = {
            'question': question,
            'documents': str(modified_documents),
            'answer': answer,
            'data_source': question_sample.get('data_source', '2wikimultihop'),
            'evidences': evid_sentences,
            'extra_info': question_sample.get('extra_info', {}),
        }
        
        if isinstance(unanswerable_sample['extra_info'], dict):
            unanswerable_sample['extra_info']['answerable'] = False
        else:
            unanswerable_sample['extra_info'] = {'answerable': False}
        
        # ç”Ÿæˆpromptç”¨äºè¿‡æ»¤
        prompt = make_prefix_unified(unanswerable_sample, template_type)
        
        # ä½¿ç”¨Best-of-Nè¯„ä¼°
        is_truly_unanswerable, best_reward = evaluate_sample_best_of_n(
            unanswerable_sample, prompt, args, llm, sampling_params, postprocessor
        )
        
        processed_count += 1
        
        if is_truly_unanswerable:
            kept_samples.append(unanswerable_sample)
            pbar.update(1)
            pbar.set_postfix({
                'ä¿ç•™': len(kept_samples),
                'ç§»é™¤': removed_count,
                'å¤„ç†': processed_count,
                'ç§»é™¤ç‡': f'{(removed_count/processed_count*100):.1f}%' if processed_count > 0 else '0.0%'
            })
        else:
            removed_count += 1
        
        idx += 1
        
        if idx >= len(dataset) - 1:
            print(f"\nâš ï¸ è­¦å‘Š: å·²éå†å®Œæ‰€æœ‰å¯ç”¨æ ·æœ¬")
            print(f"   åªè·å¾—äº†{len(kept_samples)}/{num_samples}æ¡åˆæ ¼çš„unanswerableæ ·æœ¬")
            break
    
    pbar.close()
    
    print(f"\n{'='*80}")
    print("è¿‡æ»¤ç»“æœ")
    print(f"{'='*80}")
    print(f"å¤„ç†çš„æ ·æœ¬æ€»æ•°: {processed_count}")
    print(f"ä¿ç•™çš„æ ·æœ¬(çœŸæ­£unanswerable): {len(kept_samples)}")
    print(f"ç§»é™¤çš„æ ·æœ¬(å¯è¢«å›ç­”): {removed_count}")
    print(f"ç§»é™¤ç‡: {(removed_count/processed_count*100):.1f}%" if processed_count > 0 else "ç§»é™¤ç‡: 0.0%")
    
    return kept_samples


# =========================
# Main
# =========================

def main():
    parser = argparse.ArgumentParser(description='2wikimultihop è½¬åŒ– + evidenceså¥å­åŒ–ï¼ˆä»…ä¿å­˜answerable=trueæ ·æœ¬ï¼‰')
    parser.add_argument('--type', type=str, default='train', help='trainæˆ–test')
    parser.add_argument('--template_type', type=str, default='deepseek-r1-distill-qwen')
    parser.add_argument('--size', type=int, required=True, help='ç›®æ ‡æ ·æœ¬æ€»æ•°ï¼ˆæ‰€æœ‰æ ·æœ¬å‡ä¸ºanswerable=trueï¼‰')
    
    # æ•°æ®è·¯å¾„
    parser.add_argument('--data-path', type=str, default=None, help='è¾“å…¥JSONLæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    print("\n" + "="*80)
    print("2WIKIMULTIHOP è½¬åŒ– + EVIDENCESå¥å­åŒ–")
    print("="*80)
    print(f"æ€»ç›®æ ‡æ ·æœ¬æ•°: {args.size}")
    print(f"  - Answerable(True): {args.size}")
    print("="*80)
    
    # ç¡®å®šæ•°æ®è·¯å¾„
    if args.data_path:
        data_path = args.data_path
    elif args.type == 'train':
        data_path = '/mnt/shared-storage-user/liyafu/runquan/2wikimultihop/data/train.jsonl'
    else:
        data_path = '/mnt/shared-storage-user/liyafu/runquan/2wikimultihop/data/dev.jsonl'
    
    # åŠ è½½åŸå§‹æ•°æ®é›†
    print(f"\nğŸ“‚ ä»{data_path}åŠ è½½æ•°æ®...")
    raw_dataset = Dataset.from_generator(gen_from_jsonl, gen_kwargs={'path': data_path})
    print(f"   âœ“ åŸå§‹æ•°æ®é›†é•¿åº¦: {len(raw_dataset)}")
    
    # æ‰“ä¹±å¹¶é€‰æ‹©è¶³å¤Ÿçš„æ ·æœ¬
    # ä¸ºunanswerableé¢„ç•™æ›´å¤šæ ·æœ¬ä»¥æå‡è¿‡æ»¤æˆåŠŸç‡
    total_needed = answerable_size + unanswerable_size * 10
    dataset = raw_dataset.shuffle(seed=42).select(range(min(total_needed, len(raw_dataset))))
    print(f"   âœ“ é€‰æ‹©äº†{len(dataset)}ä¸ªæ ·æœ¬ç”¨äºå¤„ç†")
    
    # æ— éœ€åˆå§‹åŒ–Best-of-Nè¿‡æ»¤ç›¸å…³çš„æ¨¡å‹å’Œåå¤„ç†å™¨
    
    # åˆå§‹åŒ–ä¸‰å…ƒç»„->å¥å­è½¬æ¢å™¨ï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®APIï¼‰
    converter = TripleSentenceConverter()
    if converter.use_api:
        print("   âœ“ Evidenceè½¬æ¢å°†ä½¿ç”¨Chat Completions API")
    else:
        print("   âš ï¸ Evidenceè½¬æ¢å°†ä½¿ç”¨å›é€€æ¨¡æ¿ï¼ˆæœªé…ç½®APIæˆ–requestsä¸å¯ç”¨ï¼‰")
    
    # åˆ›å»º answerable=True æ ·æœ¬å¹¶ä¿å­˜
    answerable_samples = create_answerable_samples(dataset, args.size, args.template_type, converter)
    
    # ç”Ÿæˆpromptå¹¶ä¿å­˜ä¸ºæ–‡ä»¶
    def build_row_with_prompt(example: dict) -> dict:
        question_prefixed = make_prefix_unified(example, template_type=args.template_type)
        return {
            "prompt": question_prefixed,
            "question": example['question'],
            "answer": example['answer'],
            "data_source": example['data_source'],
            "extra_info": example['extra_info'],
            "documents": example['documents'],
            "evidences": example['evidences'],
        }
    
    answerable_ds = Dataset.from_list(answerable_samples)
    print("\nä¸ºanswerable=Trueæ ·æœ¬ç”Ÿæˆprompt...")
    answerable_ds = answerable_ds.map(lambda ex, idx: build_row_with_prompt(ex), with_indices=True)
    
    output_dir = f'data/2wikimultihop/{args.template_type}'
    os.makedirs(os.path.expanduser(output_dir), exist_ok=True)
    
    # æ ¹æ®ç±»å‹ä¿å­˜ä¸ºtrainæˆ–testæ–‡ä»¶
    if args.type == 'train':
        output_path = os.path.join(output_dir, 'train.parquet')
    else:
        output_path = os.path.join(output_dir, 'test.parquet')
    
    answerable_ds.to_parquet(output_path)
    print(f"ğŸ’¾ å·²ä¿å­˜åˆ° {output_path} (æ ·æœ¬æ•°: {len(answerable_ds)})")
    
    # éªŒè¯
    print("\néªŒè¯ä¿å­˜ç»“æœ...")
    df = pd.read_parquet(output_path)
    n_true = sum(
        1 for _, row in df.iterrows()
        if isinstance(row.get('extra_info'), (dict, str)) and
        (json.loads(row['extra_info']) if isinstance(row['extra_info'], str) else row['extra_info']).get('answerable') is True
    )
    print(f"   âœ“ answerable=True: {n_true}/{len(df)}")
    
    print("\nâœ… å®Œæˆ!\n")


if __name__ == '__main__':
    main()